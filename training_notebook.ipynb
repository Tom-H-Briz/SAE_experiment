{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Training on MNIST\n",
    "## Sparse Autoencoder Interpretability - Phase 1\n",
    "\n",
    "This notebook trains a 4-layer ViT on MNIST with activation capture for Phase 2 SAE training.\n",
    "\n",
    "**Key outputs:**\n",
    "- Trained model weights saved in `./checkpoints/best_model.pt`\n",
    "- Layer 3 post-MLP activations ready for SAE extraction\n",
    "- Memory profiling throughout training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from local modules (ensure they're in same directory or in path)\n",
    "from config import Config, ModelConfig, TrainingConfig\n",
    "from model import ViT\n",
    "from data import get_dataloaders, inspect_batch\n",
    "from utils import (\n",
    "    set_seed, gpu_memory_report, save_checkpoint, load_checkpoint,\n",
    "    cleanup_old_checkpoints, get_device, count_parameters\n",
    ")\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create default config\n",
    "config = Config()\n",
    "\n",
    "# Optional: Override settings here\n",
    "# config.training.num_epochs = 20\n",
    "# config.training.batch_size = 64\n",
    "\n",
    "print(\"Model Config:\")\n",
    "print(f\"  Image size: {config.model.image_size}x{config.model.image_size}\")\n",
    "print(f\"  Patch size: {config.model.patch_size}x{config.model.patch_size}\")\n",
    "print(f\"  Num patches: {config.model.num_patches}\")\n",
    "print(f\"  Hidden dim: {config.model.hidden_dim}\")\n",
    "print(f\"  Num layers: {config.model.num_layers}\")\n",
    "print(f\"  Num heads: {config.model.num_heads}\")\n",
    "\n",
    "print(\"\\nTraining Config:\")\n",
    "print(f\"  Batch size: {config.training.batch_size}\")\n",
    "print(f\"  Learning rate: {config.training.learning_rate}\")\n",
    "print(f\"  Num epochs: {config.training.num_epochs}\")\n",
    "print(f\"  Mixed precision: {config.training.use_mixed_precision}\")\n",
    "print(f\"  Warmup epochs: {config.training.warmup_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Device, Seed, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "set_seed(config.training.seed)\n",
    "device = get_device()\n",
    "\n",
    "# Create model\n",
    "print(\"\\nCreating ViT model...\")\n",
    "model = ViT(config.model)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "gpu_memory_report(\"After model creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataLoaders\n",
    "print(\"Loading MNIST data...\")\n",
    "train_loader, val_loader = get_dataloaders(config)\n",
    "\n",
    "# Inspect first batch\n",
    "print(\"\\nInspecting first batch...\")\n",
    "inspect_batch(train_loader, config)\n",
    "\n",
    "gpu_memory_report(\"After data loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Overfit to 10 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test: can model overfit to 10 samples?\n",
    "print(\"Running sanity check: overfitting to 10 samples...\\n\")\n",
    "\n",
    "model_test = ViT(config.model).to(device)\n",
    "optimizer_test = optim.Adam(model_test.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get 10 samples\n",
    "images_test, labels_test = next(iter(train_loader))\n",
    "images_test = images_test[:10].to(device)\n",
    "labels_test = labels_test[:10].to(device)\n",
    "\n",
    "# Train for 50 iterations\n",
    "losses = []\n",
    "for i in range(50):\n",
    "    optimizer_test.zero_grad()\n",
    "    logits, _ = model_test(images_test)\n",
    "    loss = criterion(logits, labels_test)\n",
    "    loss.backward()\n",
    "    optimizer_test.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        acc = (logits.argmax(dim=1) == labels_test).float().mean().item()\n",
    "        print(f\"Iter {i+1:3d}: loss={loss.item():.4f}, acc={acc:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ Overfitting successful! Loss decreased from {losses[0]:.4f} to {losses[-1]:.4f}\")\n",
    "print(\"  Model architecture is working correctly.\")\n",
    "\n",
    "# Clean up\n",
    "del model_test, optimizer_test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, config):\n",
    "    \"\"\"Create Adam optimizer with weight decay.\"\"\"\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "    )\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_lr_scheduler(optimizer, config, total_steps):\n",
    "    \"\"\"Create cosine annealing scheduler with linear warmup.\"\"\"\n",
    "    warmup_steps = int(config.training.warmup_epochs * total_steps / config.training.num_epochs)\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=config.training.num_epochs,\n",
    "        T_mult=1,\n",
    "        eta_min=1e-6,\n",
    "    )\n",
    "    return scheduler, warmup_steps\n",
    "\n",
    "\n",
    "def warmup_lr(optimizer, step, warmup_steps, base_lr):\n",
    "    \"\"\"Apply linear warmup to learning rate.\"\"\"\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * (step / warmup_steps)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device, config, epoch, scaler=None):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        if config.training.use_mixed_precision and scaler is not None:\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                logits, _ = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "        else:\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.training.max_norm_grad_clip)\n",
    "        \n",
    "        # Optimizer step\n",
    "        if config.training.use_mixed_precision and scaler is not None:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        preds = logits.argmax(dim=1)\n",
    "        accuracy = (preds == labels).float().mean()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{accuracy.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    \n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion, device, config, epoch):\n",
    "    \"\"\"Validate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        if config.training.use_mixed_precision:\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                logits, _ = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "        else:\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        preds = logits.argmax(dim=1)\n",
    "        accuracy = (preds == labels).float().mean()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{accuracy.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "print(\"✓ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh model for actual training\n",
    "model = ViT(config.model).to(device)\n",
    "\n",
    "optimizer = create_optimizer(model, config)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_steps = len(train_loader) * config.training.num_epochs\n",
    "scheduler, warmup_steps = create_lr_scheduler(optimizer, config, total_steps)\n",
    "\n",
    "# Mixed precision\n",
    "scaler = None\n",
    "if config.training.use_mixed_precision and device.type == 'cuda':\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    print(\"✓ Mixed precision training enabled\")\n",
    "\n",
    "print(f\"✓ Optimizer: Adam (lr={config.training.learning_rate}, weight_decay={config.training.weight_decay})\")\n",
    "print(f\"✓ Scheduler: Cosine annealing (warmup_steps={warmup_steps})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING START\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "gpu_memory_report(\"Initial\")\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': [],\n",
    "}\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(config.training.num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device, config, epoch, scaler\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    if epoch < config.training.warmup_epochs:\n",
    "        warmup_lr(optimizer, epoch, config.training.warmup_epochs, config.training.learning_rate)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation\n",
    "    if (epoch + 1) % config.training.validate_frequency == 0:\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device, config, epoch)\n",
    "    else:\n",
    "        val_loss, val_acc = 0.0, 0.0\n",
    "    \n",
    "    # Track metrics\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['train_accuracy'].append(train_acc)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.training.num_epochs} ({epoch_time:.1f}s)\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    if val_acc > 0:\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best checkpoint\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            metrics = {\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'history': training_history,\n",
    "            }\n",
    "            save_checkpoint(\n",
    "                model, optimizer, epoch, metrics, config,\n",
    "                config.training.checkpoint_dir, best=True\n",
    "            )\n",
    "            print(f\"  ✓ New best checkpoint saved!\")\n",
    "    \n",
    "    # Save regular checkpoint\n",
    "    metrics = {\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "        'history': training_history,\n",
    "    }\n",
    "    save_checkpoint(\n",
    "        model, optimizer, epoch, metrics, config,\n",
    "        config.training.checkpoint_dir, best=False\n",
    "    )\n",
    "    \n",
    "    # Cleanup old checkpoints\n",
    "    cleanup_old_checkpoints(\n",
    "        config.training.checkpoint_dir,\n",
    "        keep_best=True,\n",
    "        keep_last_n=config.training.keep_last_n\n",
    "    )\n",
    "    \n",
    "    gpu_memory_report(f\"End of Epoch {epoch+1}\")\n",
    "\n",
    "total_time = time.time() - training_start\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "gpu_memory_report(\"Final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(training_history['train_loss'], label='Train Loss', marker='o', markersize=3)\n",
    "axes[0].plot(training_history['val_loss'], label='Val Loss', marker='s', markersize=3)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(training_history['train_accuracy'], label='Train Acc', marker='o', markersize=3)\n",
    "axes[1].plot(training_history['val_accuracy'], label='Val Acc', marker='s', markersize=3)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training & Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./training_curves.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training curves saved to training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify checkpoints were saved\n",
    "checkpoint_dir = Path(config.training.checkpoint_dir)\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob('*.pt'))\n",
    "    print(f\"Checkpoints saved: {len(checkpoints)}\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size_mb = ckpt.stat().st_size / 1e6\n",
    "        print(f\"  {ckpt.name}: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"No checkpoints directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model & Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_checkpoint_path = checkpoint_dir / 'best_model.pt'\n",
    "\n",
    "if best_checkpoint_path.exists():\n",
    "    print(f\"Loading best model from {best_checkpoint_path}...\")\n",
    "    model_loaded = ViT(config.model).to(device)\n",
    "    metadata = load_checkpoint(best_checkpoint_path, model_loaded, device=device)\n",
    "    \n",
    "    # Test inference on a single batch\n",
    "    model_loaded.eval()\n",
    "    images_test, labels_test = next(iter(val_loader))\n",
    "    images_test = images_test.to(device)\n",
    "    labels_test = labels_test.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits, _ = model_loaded(images_test)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        accuracy = (preds == labels_test).float().mean()\n",
    "    \n",
    "    print(f\"\\n✓ Best model loaded and tested\")\n",
    "    print(f\"  Test accuracy on batch: {accuracy:.4f}\")\n    print(f\"  Best epoch: {metadata['epoch']}\")\n",
    "    print(f\"  Best validation accuracy: {metadata['best_val_accuracy']:.4f}\")\nelse:\n",
    "    print(\"No best model checkpoint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Activation Capture for SAE Training\n",
    "\n",
    "The trained model is ready for Phase 2. To extract Layer 3 post-MLP activations:\n",
    "\n",
    "```python\n",
    "# Load model with activation capture\n",
    "model_capture = ViT(config.model, capture_layer=3).to(device)\n",
    "model_capture.load_state_dict(torch.load('checkpoints/best_model.pt')['model_state_dict'])\n",
    "model_capture.eval()\n",
    "\n",
    "# Extract activations from a batch\n",
    "with torch.no_grad():\n",
    "    logits, activations = model_capture(images)  # activations shape: (batch, 17, 192)\n",
    "```\n",
    "\n",
    "**Key info for ViT Prisma integration:**\n",
    "- Checkpoint path: `./checkpoints/best_model.pt`\n",
    "- Activation shape: `(batch_size, num_patches+1, hidden_dim)` = `(batch, 17, 192)`\n",
    "- Layer 3 post-MLP output is ready to train SAE on\n",
    "- Model achieved {best_val_accuracy:.1%} validation accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
